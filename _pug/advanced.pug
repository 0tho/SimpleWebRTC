extends _layout.pug

block vars
  - var pageDescription = 'SimpleWebRTC'
  - var bodyClass = 'page-advanced'
  - var headerClass = 'advanced'

block title
  | Advanced SimpleWebRTC

block content

  include includes/header

  .container

    section
      p Sometimes, the basic usage is not enough. You need more control than. Let's talk about this. <a href="https://andyet.com/">We</a> use a lot of the things shown here on <a href="https://talky.io/">Talky</a>.
      p Some use cases are not supported by all browsers yet or we have not found a nice API that we want to use.

      h3 Do not use the default sandbox signaling server in production
      p The signaling server is a server that helps the two browsers exchange a small amount of information they need to connect to each other in a secure manner.
      p We provide a sandbox signaling server so it easy to get started. However, installing <a href="https://github.com/andyet/signalmaster">Signalmaster</a> is one of the first things to do when you want to dive deeper. Then just point the url attribute in the SimpleWebRTC constructor to your server url:

      h3 A dab of HTML
      :markdown-it(linkify langPrefix='hljs ')
        ```js
          var webrtc = new SimpleWebRTC({
            // the id/element dom element that will hold "our" video
            localVideoEl: 'localVideo',
            // the id/element dom element that will hold remote videos
            remoteVideosEl: 'remotesVideos',
            // immediately ask for camera access
            autoRequestMedia: true,
            url: 'https://example.com/'
          });
        ```      

    section
      h3 Add style your video element
      p Most of the time, you want to wrap your video element in a container, e.g. to add overlays instead of just having raw unstyled video elements in your remote video container.
      p To do this, you need to supress adding them to the remote video container by passing an empty string for the container id:
      :markdown-it(linkify langPrefix='hljs ')
        ```js
          var webrtc = new SimpleWebRTC({
            localVideoEl: 'localVideo',
            remoteVideosEl: '' // empty string
          });
        ```     

      p Then, you need to hook the <strong>videoAdded</strong> event. It is called with the video element and the peer session as an argument:
      :markdown-it(linkify langPrefix='hljs ')
        ```js
          // a peer video has been added
          webrtc.on('videoAdded', function (video, peer) {
              console.log('video added', peer);
              var remotes = document.getElementById('remotes');
              if (remotes) {
                  var container = document.createElement('div');
                  container.className = 'videoContainer';
                  container.id = 'container_' + webrtc.getDomId(peer);
                  container.appendChild(video);

                  // suppress contextmenu
                  video.oncontextmenu = function () { return false; };

                  remotes.appendChild(container);
              }
          });
        ```   

      p You create div element, set a className so you can style all video containers using CSS and add an id so you can remove that video element later on.
      :markdown-it(linkify langPrefix='hljs ')
        ```js
          // a peer video was removed
          webrtc.on('videoRemoved', function (video, peer) {
              console.log('video removed ', peer);
              var remotes = document.getElementById('remotes');
              var el = document.getElementById(peer ? 'container_' + webrtc.getDomId(peer) : 'localScreenContainer');
              if (remotes && el) {
                  remotes.removeChild(el);
              }
          });
        ``` 
      
      p Lets add a little CSS so you can create overlays in the next step:
      :markdown-it(linkify langPrefix='hljs ')
        ```css
          .videoContainer {
              position: relative;
              width: 200px;
              height: 150px;
          }
          .videoContainer video {
              position: absolute;
              width: 100%;
              height: 100%;
          }
        ``` 

      p See <a href='/demo'>the demo page</a> for a complete example.

    section
      h3 Show more information about the state of the connection
      p The way the <a href='https://w3c.github.io/webrtc-pc/'>RTCPeerConnection API</a> works you get the stream (and therefore the video element) before the P2P connection is fully established. Therefore it's a good idea to display information about the state of the connection as done on <a href='/demo'>the demo page</a>. Just extend the previous example a little bit by adding the following piece of code in the videoAdded event:

      :markdown-it(linkify langPrefix='hljs ')
        ```js
          // show the ice connection state
          if (peer && peer.pc) {
              var connstate = document.createElement('div');
              connstate.className = 'connectionstate';
              container.appendChild(connstate);
              peer.pc.on('iceConnectionStateChange', function (event) {
                  switch (peer.pc.iceConnectionState) {
                  case 'checking':
                      connstate.innerText = 'Connecting to peer...';
                      break;
                  case 'connected':
                  case 'completed': // on caller side
                      connstate.innerText = 'Connection established.';
                      break;
                  case 'disconnected':
                      connstate.innerText = 'Disconnected.';
                      break;
                  case 'failed':
                      break;
                  case 'closed':
                      connstate.innerText = 'Connection closed.';
                      break;
                  }
              });
          }
        ``` 

      p This code adds an overlay inside the video container that visualized the connection state. Whenever the connection state changes, the callback for the iceConnectionStateChange will be called and you can inspect the new state of the connection. Note that some events like <strong>connected</strong> or <strong>disconnected</strong> can be called multiple times when there are short interruptions in connectivity. Now let's just add another bit of CSS:

      :markdown-it(linkify langPrefix='hljs ')
        ```css
          .connectionstate {
              position: absolute;
              top: 0px;
              width: 100%;
              text-align: center;
              color: #fff
          }
        ``` 

      p This positions the displayed at the top of the video container, centers it and makes it white. Of course, you can display it any other way you want, it just depends on your CSS magic.

      p The <strong>failed</strong> state is somewhat special. In Chrome, this can only occur on the initiating side whereas in Firefox it can happen on both sides. SimpleWebRTC abstracts this by providing two events for this:

      :markdown-it(linkify langPrefix='hljs ')
        ```js
          // local p2p/ice failure
          webrtc.on('iceFailed', function (peer) {
              var connstate = document.querySelector('#container_' + webrtc.getDomId(peer) + ' .connectionstate');
              console.log('local fail', connstate);
              if (connstate) {
                  connstate.innerText = 'Connection failed.';
                  fileinput.disabled = 'disabled';
              }
          });

          // remote p2p/ice failure
          webrtc.on('connectivityError', function (peer) {
              var connstate = document.querySelector('#container_' + webrtc.getDomId(peer) + ' .connectionstate');
              console.log('remote fail', connstate);
              if (connstate) {
                  connstate.innerText = 'Connection failed.';
                  fileinput.disabled = 'disabled';
              }
          });
        ``` 

      p For the purpose of the sample, this is just handled by showing it to the user.

  section
    h3 Show audio levels
    p Another thing that is nice to show is the audio level of a participant. Due to <a href='https://code.google.com/p/chromium/issues/detail?id=121673'>some restrictions in Chrome</a>, it is currently only available from local mediastreams and not from MediaStreams received via a WebRTC peerconnections.
    p We are going to use <a href='https://github.com/otalk/hark'>hark</a>, an awesome Javascript module, to extract the audio level from the MediaStream with the WebAudio API. One of the advantage of this over other techniques (like querying the PeerConnections getStats method) is that it does not require an established peer-to-peer connection and therefore can be used in a screen that allows the users to check their microphone before joining a conference (see <a href='https://talky.io/'>the haircheck screen on Talky</a> for an example).
    p Since we will have different sources for the volume, let's start with a helper function that changes the height of a value of a HTML5 <strong>meter</strong> element that is overlayed ontop of the video element:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // helper function to show the volume
        function showVolume(el, volume) {
            console.log('showVolume', volume, el);
            if (!el) return;
            if (volume < -45) volume = -45; // -45 to -20 is
            if (volume > -20) volume = -20; // a good range
            el.value = volume;
        }
      ``` 

    p See the <a href='https://github.com/otalk/hark#understanding-dbvolume-threshold'>hark documentation</a> for the meaning of the volume parameter and play around with the parameters a little.
    p Next, add a little bit of CSS:

    :markdown-it(linkify langPrefix='hljs ')
      ```css
        .volume {
            position: absolute;
            left: 15%;
            width: 70%;
            bottom: 2px;
            height: 10px;
        }
      ``` 

    p And we need to create this volume meter element when creating the remote video, so add the following piece of code in the videoAdded element:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // show the remote volume
        var vol = document.createElement('meter');
        vol.id = 'volume_' + peer.id;
        vol.className = 'volume';
        vol.min = -45;
        vol.max = -20;
        vol.low = -40;
        vol.high = -25;
        container.appendChild(vol);
      ``` 

    p <a href='/demo'>See the demo</a> for the full code. If you test this make sure you open the page in two different windows, not tabs, since browsers limit the number of times callbacks are executed in background pages.
    p Now, hook it up with the localStream. SimpleWebRTC includes hark and lets you subscribe to a <strong>volumeChange</strong> event:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // remote volume has changed
        webrtc.on('remoteVolumeChange', function (peer, volume) {
            showVolume(document.getElementById('volume_' + peer.id), volume);
        });
      ``` 

    p That's it. Showing the remote volume helps you visually identify noisy participants and allows you to mute them.

  section
    h2 All about muting
    p There are a number of usecases where you want to mute either your own audio/video stream or the stream of a remote participant. Let's look at those in detail.
    p Muting your own audio is pretty easy. To mute, just call:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        webrtc.mute()
      ``` 

    p and to unmute call:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        webrtc.unmute()
      ``` 

    p Pretty simple, eh? If you hook it up to a button, make sure you wrap іt inside a function which just toggles a muted state.
    p Turning video on and off works similar, use the <code class='code-light'>.pauseVideo()</code> and <code class='code-light'>.resumeVideo()</code> methods to control the video:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        webrtc.pauseVideo();
        webrtc.resumeVideo();
      ``` 

    p Now, if you want to mute your audio and not send video there is a shortcut for that. The <code class='code-light'>.pause()</code> and <code class='code-light'>.resume()</code> methods. Unfortunately, this modifies both your muted and video send state, so make sure you keep track of those states.

    p Internally, the mute methods work by changing the audio or video tracks <strong>.enabled</strong> flag. Setting this flag to false causes WebRTC implementations to send silence (for audio) and black frames (for video). This requires relatively little bandwidth.

    p So now you are no longer sending audio and video. Wouldn't it be nice if the remote side was notified of that so it could do something more useful than displaying a black frame?

    p Whenever you mute or unmute someone, a message is sent via the signaling channel. Listening for this message is easy:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // listen for mute and unmute events
        webrtc.on('mute', function (data) { // show muted symbol
          webrtc.getPeers(data.id).forEach(function (peer) {
            if (data.name == 'audio') {
              $('#videocontainer_' + webrtc.getDomId(peer) + ' .muted').show();
            } else if (data.name == 'video') {
              $('#videocontainer_' + webrtc.getDomId(peer) + ' .paused').show();
              $('#videocontainer_' + webrtc.getDomId(peer) + ' video').hide();
            }
          });
        });
        webrtc.on('unmute', function (data) { // hide muted symbol
          webrtc.getPeers(data.id).forEach(function (peer) {
            if (data.name == 'audio') {
              $('#videocontainer_' + webrtc.getDomId(peer) + ' .muted').hide();
              } else if (data.name == 'video') {
                  $('#videocontainer_' + webrtc.getDomId(peer) + ' video').show();
                  $('#videocontainer_' + webrtc.getDomId(peer) + ' .paused').hide();
              }
            });
        });
      ``` 

    p This uses jQuery to show and hide mute symbols as overlays ontop the video. Again, those elements need to be created in the videoAdded event:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // add muted and paused elements
        var muted = document.createElement('span');
        vol.className = 'muted';
        container.appendChild(muted);

        var muted = document.createElement('span');
        vol.className = 'muted';
        container.appendChild(muted);
      ``` 

    p and styled with a little CSS:    

    :markdown-it(linkify langPrefix='hljs ')
      ```css
        .muted, .paused
            display: none
            position: absolute
            z-index: 1
            color: #12acef

        .muted
            left: 0px
            bottom: 10%
            width: 100%

        .paused
            left: 0px
            top: 40%
            width: 100%
      ``` 

    p For the local video, similar events are available:
    :markdown-it(linkify langPrefix='hljs ')
      ```js
        //local mute/unmute events
        webrtc.on('audioOn', function () {
            // your local audio just turned on
        });
        webrtc.on('audioOff', function () {
            // your local audio just turned off
        });
        webrtc.on('videoOn', function () {
            // local video just turned on
        });
        webrtc.on('videoOff', function () {
            // local video just turned off
        });
      ```

    p By the way, if you are looking for a way to mute a remote participant that is even easier. Just set the video element volume to 0.

  section
    h2 Filetransfer
    p Filetransfer refers to sending a file to a single peer. If you want to share the same file with multiple participants, uploading it to a server is most likely a better way to do it. Or implementing something like <a href='https://webtorrent.io/'>Bittorrent over WebRTC</a>. Using the following technique to share a file with multiple participants works, but will be limited by the upload speed.
    p Let's start with a modified version of the basic SimpleWebRTC HTML structure:

    :markdown-it(linkify langPrefix='hljs ')
      ```html
        <!DOCTYPE html>
        <html>
            <head>
                <script src="https://simplewebrtc.com/latest-v2.js"></script>
            </head>
            <body>
                <div id="remotes"></div>
            </body>
        </html>
      ```

    p Next, lets create the SimpleWebRTC object. This time, we don't want audio or video, so we set autoRequestMedia to false and also tweak the receive options:

   
    :markdown-it(linkify langPrefix='hljs ')
      ```js
        var webrtc = new SimpleWebRTC({
            // we don't do video
            localVideoEl: '',
            remoteVideosEl: '',
            // dont ask for camera access
            autoRequestMedia: false
            // dont negotiate media
            receiveMedia: {
                offerToReceiveAudio: 0,
                offerToReceiveVideo: 0
            }
        });
      ``` 

    p Since the readyToJoin callback relies on having access to the camera we just ignore it and join the room directly:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // join without waiting for media
        webrtc.joinRoom('your awesome room name');
      ``` 

    p This will join the room and create a connection with every peer that joins. So let's wait for a peer to join:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // called when a peer is created
        webrtc.on('createdPeer', function (peer) {
            console.log('createdPeer', peer);
        });
      ```
    p See the <a href='/file-demo'>file transfer</a> demo for the full implementation. Now we can do two things with this peer:

    ul.bullet-list
      li send them a file and 
      li receive a file from them.

    p Let's look at the receive part first:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // receiving an incoming filetransfer
        peer.on('fileTransfer', function (metadata, receiver) {
            console.log('incoming filetransfer', metadata.name, metadata);
            receiver.on('progress', function (bytesReceived) {
                console.log('receive progress', bytesReceived, 'out of', metadata.size);
            });
            // get notified when file is done
            receiver.on('receivedFile', function (file, metadata) {
                console.log('received file', metadata.name, metadata.size);

                // close the channel
                receiver.channel.close();
            });
            filelist.appendChild(item);
        });
      ```

    p The filetransfer event is called with some metadata about the file (such as the filename and the size) and a receiver object. This receiver object emits two events: progress and receivedFile:

    ul.bullet-list
      li <strong>progress</strong> is called whenever receiving data from the peer. It can be hooked up to a HTML5 <code class='code-light'>progress</code> element quite nicely as shown in the demo.
      li <strong>receivedFile</strong> is called when the transfer is complete. Its arguments are a blob object of the file and the metadata. The file can then be easily made available for download by creating an <code class='code-light'>a</code> element and setting the href attribute to a url created with <code class='code-light'>URL.createObjectURL(file)</code>

    p That was easy, wasn't it? Lets look at sending the file next.
    p First, we need the user to select a file to transfer. This is done with an <code class='code-light'>input</code> element:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // select a file
        var fileinput = document.createElement('input');
        fileinput.type = 'file';
      ```

    p We then need to listen for the change event on that filelistener:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // send a file
        fileinput.addEventListener('change', function() {
            fileinput.disabled = true;

            var file = fileinput.files[0];
            var sender = peer.sendFile(file);
        });
      ```   

    p Actually, that's it. Most of the work is again making a nice UI for it. The sender object returned by sendFile emits three events:

    ul.bullet-list
      li progress,
      li sentFile,
      li complete

    p <strong>progress</strong> can again be hooked up to a progress bar. <strong>sentFile</strong> indicates that the sender considers the transfer to be complete. Due to internal buffering this may sometimes happen before the receiver has received the complete file. Therefore it is not safe to close the connection before receiving the <strong>complete</strong> event.

    p Building a nice filetransfer application with this is pretty easy. Note that the demo does not fall back to using TURN servers. While that is pretty much required for doing voice-over-ip, for filetransfer it might actually be better to relay encrypted file chunks via third parties.

  section
    h2 Share your screen
    p Sharing your screen is simple, but requires a small amount of work outside of your application. Browsers support this in different ways. Capturing screen media requires your application to be running on https.

    h3 Chrome
    p Chrome exposes APIs for screen sharing through the <a href='https://developer.chrome.com/extensions/desktopCapture'>desktopCapture extension API</a>. <a href='https://github.com/HenrikJoreteg/getScreenMedia/'>getScreenMedia</a> contains <a href='https://github.com/HenrikJoreteg/getScreenMedia/tree/master/chrome-extension-sample'>a Chrome extension sample</a> for enabling screen capture in Chrome.

    p To run the extension for your application, you just have to <a href='https://developer.chrome.com/extensions/getstarted#unpacked'>load the extension example</a>, and modify the manifest file to match your development url:

    :markdown-it(linkify langPrefix='hljs ')
      ```json
        "content_scripts": [ {
            "js": [ "content.js" ],
            "matches": [ "https://localhost:*/*" ]
          }]
        });
      ```   

    p Older versions of Chrome used a flag called enable-usermedia-screen-capture. This is no longer the supported mechanism for screen capture in Chrome, but is still used in Chromium Embedded Framework and Node Webkit applications.

    h3 Firefox
    p Firefox enables screen media capturing through the <code class='code-light'>media.getusermedia.screensharing.allowed_domains</code> config setting. This can be modified automatically via an add-on, or it can be modified manually by navigating to <code class='code-light'>about:config</code> in Firefox. Modifying the setting manually to add <code class='code-light'>localhost</code> is easiest for development.

    p <a href='https://github.com/HenrikJoreteg/getScreenMedia/'>getScreenMedia</a> also contains a <a href='https://github.com/HenrikJoreteg/getScreenMedia/tree/master/firefox-extension-sample'>Firefox extension sample</a>. Just modify the <code class='code-light'>boostrap.js</code> to match your domain:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        var domains = ["simplewebrtc.com"];
      ```   

    h3 Starting screen share
    p Wire up an event handler or action for a user to initiate screen sharing. Here, we have a button to be disabled when screen sharing is unavailable, and to start sharing screen when clicked:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        var button = document.getElementById('screenShareButton'),
            setButton = function (bool) {
                button.innerText = bool ? 'share screen' : 'stop sharing';
            };
        if (!webrtc.capabilities.supportScreenSharing) {
            button.disabled = 'disabled';
        }
        webrtc.on('localScreenRemoved', function () {
            setButton(true);
        });

        setButton(true);

        button.click(function () {
            if (webrtc.getLocalScreen()) {
                webrtc.stopScreenShare();
                setButton(true);
            } else {
                webrtc.shareScreen(function (err) {
                    if (err) {
                        setButton(true);
                    } else {
                        setButton(false);
                    }
                });

            }
        });
      ```  

    p Then, you need to hook the <strong>localScreenAdded</strong> and <strong>localScreenRemoved</strong> events for adding and removing the local screen video element to the page: 

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // local screen obtained
        webrtc.on('localScreenAdded', function (video) {
          video.onclick = function () {
            video.style.width = video.videoWidth + 'px';
            video.style.height = video.videoHeight + 'px';
          };
          document.getElementById('localScreenContainer').appendChild(video);
          $('#localScreenContainer').show();
        });
        // local screen removed
        webrtc.on('localScreenRemoved', function (video) {
          document.getElementById('localScreenContainer').removeChild(video);
          $('#localScreenContainer').hide();
        });
      ```  

    p You can style and show connection states for the screen sharing video elements similar to the examples above for video.

  section
    h2 Selecting a microphone and camera
    p The first step to selecting media input devices is to enumerate sources which is done in a callback passed to <code class='code-light'>navigator.mediaDevices.enumerateDevices</code>. Separate and label audio and video devices:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        var audioDevices = [],
          videoDevices = [];
          navigator.mediaDevices.enumerateDevices().then(function (devices) {
            for (var i = 0; i !== devices.length; ++i) {
              var device = devices[i];
              if (device.kind === 'audioinput') {
                device.label = device.label || 'microphone ' + (audioDevices.length + 1);
                  audioDevices.push(device);
                } else if (device.kind === 'videoinput') {
                  device.label = device.label || 'camera ' + (videoDevices.length + 1);
                  videoDevices.push(device);
                }
            }
          });
        }
      ```  

    p Note that device labels are empty if you do not yet have permission to access the camera or microphone.
    p You can then use these audio and video devices to populate a selection UI like a <code class='code-light'>select</code> tag, e.g. as shown here. For example simplicity, we'll assume you can populate the UI with options and extract the selected option.
    p Once you have the selected option, the user can trigger starting the connection. You'll create the SimpleWebRTC object similar to the basic example, but with additional options passed to the <strong>media</strong> option:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        //default media options
        var mediaOptions = {
            audio: true,
            video: true
        };
        if (selectedAudioDevice && selectedAudioDevice.sourceId) {
            mediaOptions.audio = {
                deviceId: selectedAudioDevice.deviceId
            };
        }
        if (selectedVideoDevice && selectedVideoDevice.sourceId) {
            mediaOptions.video = {
                deviceId: selectedDevice.deviceId
            };
        }
        var webrtc = new SimpleWebRTC({
          localVideoEl: 'localVideo',
          remoteVideosEl: 'remotesVideos',
          autoRequestMedia: true,
          url: 'https://example.com/'
          //use the media options to pass constraints for getUserMedia requests
          media: mediaOptions
        });
      ```

    p Now, when SimpleWebRTC requests user media from the browser, it will request the specific devices selected by the user.

  section
    h2 Fail, with grace
    p Sometimes, connections fail. While there is little you can do about that, you can make some educated guesses about <strong>the why</strong>. Most of the time, this is caused by one of the peers being on a restriced network. In that case (and assuming that you are using a TURN server) the PeerConnection will not have gathered any candidates of type relay. SimpleWebRTC makes very easy to detect by exposing a <code class='code-light'>hadLocalRelayCandidate</code> and <code class='code-light'>hadRemoteRelayCandidate</code> property which can be checked when ICE fails:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        // local p2p/ice failure
        webrtc.on('iceFailed', function (peer) {
            var pc = peer.pc;
            console.log('had local relay candidate', pc.hadLocalRelayCandidate);
            console.log('had remote relay candidate', pc.hadRemoteRelayCandidate);
        });

        // remote p2p/ice failure
        webrtc.on('connectivityError', function (peer) {
            var pc = peer.pc;
            console.log('had local relay candidate', pc.hadLocalRelayCandidate);
            console.log('had remote relay candidate', pc.hadRemoteRelayCandidate);
        });
      ```

    p Based on this, you can determine which end of the connection is behind a restricted network.
    p For more details (than you ever wanted to know) <a href='http://www.tokbox.com/blog/failed-techtok-with-philipp-hancke/'>watch this talk</a>.

  section
    h2 User-friendly nicknames
    p Sometimes, you want to display a nickname along with the video. That's now pretty simple, just add a 'nick' property to the config when creating the SimpleWebRTC object:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        var webrtc = new SimpleWebRTC({
          // the id/element dom element that will hold "our" video
          localVideoEl: 'localVideo',
          // the id/element dom element that will hold remote videos
          remoteVideosEl: 'remotesVideos',
          // immediately ask for camera access
          autoRequestMedia: true,
          nick: 'Jane Doe',
          url: 'https://example.com/'
        });
      ```

    p and evaluate peer.nick in the <strong>videoAdded</strong> event:

    :markdown-it(linkify langPrefix='hljs ')
      ```js
        webrtc.on('videoAdded', function (video, peer) {
          console.log('videoAdded', peer.nick);
        });
      ```

    p Join without a camera or microphone
    p Connection quality
    p Upgrade an audiochat to a videochat
    p Text chat
    p Data channels
    p Integrate it: reveal.js
    p Let's talk about TURN servers...
    p A word about mobile apps
    p Full Mesh or Full Mess? Advanced Multiparty
    p Recording a conference

  include includes/footer
